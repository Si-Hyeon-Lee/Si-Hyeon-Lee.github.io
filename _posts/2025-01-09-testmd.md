```python
import torch
import torchvision
import torchvision.transforms as transforms
import numpy
import matplotlib.pyplot as plt
device = 'cuda' if torch.cuda.is_available() is True else 'cpu'
device
```




    'cuda'




```python
batch_size = 128
num_epoch = 50
lr = 1e-3
```


```python
transformer = transforms.Compose(
    [
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(), #  (H x W x C)in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] 
        transforms.Normalize( (0.5,0.5,0.5),(0.5,0.5,0.5),)
    ]
)
train_set = torchvision.datasets.CIFAR10(root='../nvme/data/CIFAR10/',train=True,transform=transformer,download=True)
test_set = torchvision.datasets.CIFAR10(root='../nvme/data/CIFAR10/',train=False,transform=transformer,download=True)

train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True,num_workers=4,pin_memory=True)
test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=False,num_workers=4,pin_memory=True)
```

    Files already downloaded and verified
    Files already downloaded and verified



```python
# def imshow(img:torch.Tensor):
#     img =  img/2 +0.5 #  plt.imshow는 [0, 1] 범위의 값을 직접적으로 이미지로 처리할 수 있습니다. plt.imshow((img * 255).astype(np.uint8))
#     npimg = img.numpy()
#     plt.imshow(npimg.transpose((1,2,0))) # C H W  to H W C
#     plt.show()

# train_data_iterator = iter(train_loader)
# img_,label_ = next(train_data_iterator)
# imshow(img_[1])
```


```python
import models
model = models.ResNet50().to(device)
model_name = 'ResNet50'
# import torchvision.models as models
# model = models.res(num_classes = 10).to(device)
# model_name = 'VGG'
# print(model)
```

# Optimizer And Loss Function Definition


```python
import torch.nn as nn
import torch.optim as optim
import torchmetrics

criterion = nn.CrossEntropyLoss().to(device) # logits and target
optimizer = optim.Adam(model.parameters(),lr=lr,weight_decay=1e-4) 
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epoch)
accuracy_metric = torchmetrics.Accuracy('multiclass',threshold=0.5,num_classes=10).to(device)
```


```python
best_acc = 0.85
for epoch in range(num_epoch):
    eval_loss = 0.0
    accuracy_metric.reset() # 이렇게 해줘야함. torchmetrics 친구들
    model.eval()
    with torch.no_grad():
        for i,(img,label) in enumerate(test_loader):
            img,label = img.to(device) , label.to(device)
            logits = model(img)
            #print(logits.shape)
            #print(label.shape)
            loss=criterion(logits,label)
            eval_loss+= loss.item()
            p=torch.softmax(logits,1)
            accuracy_metric.update(p,label)
    eval_acc = accuracy_metric.compute()
    print(f'Epoch {epoch} Eval Loss : {eval_loss/(i+1):.3f} Accuracy : {eval_acc:.2f}')
    if  eval_acc > best_acc:
        best_acc = eval_acc
        torch.save(model.state_dict(),f'./models/{model_name}_acc:{best_acc:.2f}.pth')
        print('Saved Model')

    train_loss = 0.0
    accuracy_metric.reset()
    model.train()
    for i ,(img,label) in enumerate(train_loader):
        optimizer.zero_grad()
        img,label = img.to(device) , label.to(device)
        logits = model(img)
        loss = criterion(logits,label)
        loss.backward()
        optimizer.step()
        train_loss  += loss.item()
        accuracy_metric.update(torch.softmax(logits,1),label)
    scheduler.step()
    train_acc = accuracy_metric.compute()
    print(f'\tTrain Loss : {train_loss/(i+1):.3f} , Trian Acc : {train_acc:.3f}')
```

    Epoch 0 Eval Loss : 2.303 Accuracy : 0.10
    	Train Loss : 1.664 , Trian Acc : 0.391
    Epoch 1 Eval Loss : 1.332 Accuracy : 0.52
    	Train Loss : 1.113 , Trian Acc : 0.600
    Epoch 2 Eval Loss : 1.179 Accuracy : 0.59
    	Train Loss : 0.888 , Trian Acc : 0.684
    Epoch 3 Eval Loss : 0.889 Accuracy : 0.69
    	Train Loss : 0.753 , Trian Acc : 0.736
    Epoch 4 Eval Loss : 0.743 Accuracy : 0.74
    	Train Loss : 0.664 , Trian Acc : 0.770
    Epoch 5 Eval Loss : 0.730 Accuracy : 0.75
    	Train Loss : 0.592 , Trian Acc : 0.795
    Epoch 6 Eval Loss : 0.675 Accuracy : 0.77
    	Train Loss : 0.550 , Trian Acc : 0.809
    Epoch 7 Eval Loss : 0.676 Accuracy : 0.77
    	Train Loss : 0.518 , Trian Acc : 0.822
    Epoch 8 Eval Loss : 0.620 Accuracy : 0.79
    	Train Loss : 0.481 , Trian Acc : 0.835
    Epoch 9 Eval Loss : 0.636 Accuracy : 0.78
    	Train Loss : 0.456 , Trian Acc : 0.843
    Epoch 10 Eval Loss : 0.533 Accuracy : 0.81
    	Train Loss : 0.433 , Trian Acc : 0.851
    Epoch 11 Eval Loss : 0.501 Accuracy : 0.83
    	Train Loss : 0.407 , Trian Acc : 0.860
    Epoch 12 Eval Loss : 0.582 Accuracy : 0.81
    	Train Loss : 0.392 , Trian Acc : 0.865
    Epoch 13 Eval Loss : 0.524 Accuracy : 0.83
    	Train Loss : 0.368 , Trian Acc : 0.873
    Epoch 14 Eval Loss : 0.495 Accuracy : 0.83
    	Train Loss : 0.349 , Trian Acc : 0.881
    Epoch 15 Eval Loss : 0.451 Accuracy : 0.85
    	Train Loss : 0.332 , Trian Acc : 0.885
    Epoch 16 Eval Loss : 0.463 Accuracy : 0.84
    	Train Loss : 0.315 , Trian Acc : 0.891
    Epoch 17 Eval Loss : 0.443 Accuracy : 0.85
    	Train Loss : 0.300 , Trian Acc : 0.897
    Epoch 18 Eval Loss : 0.453 Accuracy : 0.85
    	Train Loss : 0.281 , Trian Acc : 0.903
    Epoch 19 Eval Loss : 0.418 Accuracy : 0.86
    	Train Loss : 0.267 , Trian Acc : 0.907
    Epoch 20 Eval Loss : 0.396 Accuracy : 0.87
    	Train Loss : 0.251 , Trian Acc : 0.914
    Epoch 21 Eval Loss : 0.375 Accuracy : 0.87
    	Train Loss : 0.235 , Trian Acc : 0.918
    Epoch 22 Eval Loss : 0.364 Accuracy : 0.88
    	Train Loss : 0.223 , Trian Acc : 0.923
    Epoch 23 Eval Loss : 0.374 Accuracy : 0.87
    	Train Loss : 0.207 , Trian Acc : 0.927
    Epoch 24 Eval Loss : 0.349 Accuracy : 0.89
    	Train Loss : 0.191 , Trian Acc : 0.933
    Epoch 25 Eval Loss : 0.360 Accuracy : 0.88
    	Train Loss : 0.181 , Trian Acc : 0.937
    Epoch 26 Eval Loss : 0.349 Accuracy : 0.89
    	Train Loss : 0.167 , Trian Acc : 0.943
    Epoch 27 Eval Loss : 0.327 Accuracy : 0.89
    	Train Loss : 0.152 , Trian Acc : 0.946
    Epoch 28 Eval Loss : 0.318 Accuracy : 0.90
    	Train Loss : 0.138 , Trian Acc : 0.952
    Epoch 29 Eval Loss : 0.310 Accuracy : 0.90
    	Train Loss : 0.130 , Trian Acc : 0.954
    Epoch 30 Eval Loss : 0.313 Accuracy : 0.90
    	Train Loss : 0.119 , Trian Acc : 0.958
    Epoch 31 Eval Loss : 0.316 Accuracy : 0.90
    	Train Loss : 0.104 , Trian Acc : 0.964
    Epoch 32 Eval Loss : 0.318 Accuracy : 0.91
    	Train Loss : 0.091 , Trian Acc : 0.968
    Epoch 33 Eval Loss : 0.299 Accuracy : 0.91
    	Train Loss : 0.081 , Trian Acc : 0.971
    Epoch 34 Eval Loss : 0.299 Accuracy : 0.91
    	Train Loss : 0.073 , Trian Acc : 0.975
    Epoch 35 Eval Loss : 0.296 Accuracy : 0.91
    	Train Loss : 0.064 , Trian Acc : 0.978
    Epoch 36 Eval Loss : 0.311 Accuracy : 0.91
    	Train Loss : 0.054 , Trian Acc : 0.982
    Epoch 37 Eval Loss : 0.298 Accuracy : 0.92
    	Train Loss : 0.048 , Trian Acc : 0.984
    Epoch 38 Eval Loss : 0.301 Accuracy : 0.92
    	Train Loss : 0.040 , Trian Acc : 0.986
    Epoch 39 Eval Loss : 0.292 Accuracy : 0.92
    	Train Loss : 0.033 , Trian Acc : 0.989
    Epoch 40 Eval Loss : 0.306 Accuracy : 0.92
    	Train Loss : 0.029 , Trian Acc : 0.991
    Epoch 41 Eval Loss : 0.289 Accuracy : 0.92
    	Train Loss : 0.026 , Trian Acc : 0.992
    Epoch 42 Eval Loss : 0.290 Accuracy : 0.92
    	Train Loss : 0.021 , Trian Acc : 0.994
    Epoch 43 Eval Loss : 0.305 Accuracy : 0.92
    	Train Loss : 0.018 , Trian Acc : 0.995
    Epoch 44 Eval Loss : 0.293 Accuracy : 0.92
    	Train Loss : 0.016 , Trian Acc : 0.996
    Epoch 45 Eval Loss : 0.292 Accuracy : 0.93
    	Train Loss : 0.014 , Trian Acc : 0.996
    Epoch 46 Eval Loss : 0.296 Accuracy : 0.93
    	Train Loss : 0.013 , Trian Acc : 0.997
    Epoch 47 Eval Loss : 0.297 Accuracy : 0.92
    	Train Loss : 0.012 , Trian Acc : 0.997
    Epoch 48 Eval Loss : 0.294 Accuracy : 0.93
    	Train Loss : 0.011 , Trian Acc : 0.997
    Epoch 49 Eval Loss : 0.299 Accuracy : 0.93
    	Train Loss : 0.011 , Trian Acc : 0.997

